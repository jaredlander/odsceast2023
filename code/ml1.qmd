---
title: ML in R
author: Jared P. Lander
date: today
date-format: long
format:
    html: 
      toc: true
      number-sections: true
---

# Data

```{r}
data(credit_data, package='modeldata')

credit <- tibble::as_tibble(credit_data)
credit
```

```{r}
library(dplyr)
```

```{r}
fake_customers <- credit |> 
    select(-Status) |> 
    slice_sample(n=10)
fake_customers
```

Split the data

```{r}
library(rsample)

set.seed(37)
data_split <- initial_split(
    credit, 
    prop=0.8,
    strata='Status'
)
data_split

train <- training(data_split)
test <- testing(data_split)

train
test
```

# EDA

Now we use our favorite packages, `{dplyr}` and `{ggplot2}`

```{r}
library(ggplot2)
ggplot(train, aes(x=Status)) + geom_bar()
```

There are a lot more good than bad, could be a problem

```{r}
train |> count(Status)
```

```{r}
ggplot(train, aes(x=Amount, y=Age, color=Status)) + 
    geom_point()
```

```{r}
library(corrr)
correlate(train)
correlate(train) |> autoplot()
correlate(train) |> network_plot()
```

# Feature Engineering

Outcome:

- target
- response
- class
- y
- label
- dependent variable

Input:

- independent variable
- features
- x
- covariates
- predictor

coefficients == weights (ML)

intercept == bias

inverse logit == sigmoid

Dummy variables == indicator variables == one hot encoded

```{r}
train |> count(Home)

train |> select(Home)

train |> select(Home) |> head(n=10) |> 
    model.matrix( ~ Home, data=_)
```

`{recipes}`

```{r}
library(recipes)

rec1 <- recipe(Status ~ ., data=train) |> 
    # not really needed for xgboost, but good for 
    # other methods
    themis::step_downsample(Status, under_ratio=1.2) |> 
    step_nzv(all_predictors()) |> 
    step_filter_missing(all_predictors(), threshold=.5) |> 
    step_unknown(
        all_nominal_predictors(), 
        new_level='missing'
    ) |> 
    step_impute_knn(all_numeric_predictors()) |> 
    step_normalize(all_numeric_predictors()) |> 
    # step_center() |> step_scale() |> 
    step_other(all_nominal_predictors(), other='misc') |> 
    step_novel(
        all_nominal_predictors(), new_level='unseen'
    ) |> 
    step_dummy(
        all_nominal_predictors(), 
        one_hot=TRUE
    )

rec1

rec1 |> prep()
rec1 |> prep() |> bake(new_data=NULL)
# rec1 |> prep() |> bake(new_data=NULL) |> View()
```


# Define the Model

xgboost

```{r}
library(parsnip)

linear_reg()
linear_reg() |> set_engine('lm')
linear_reg() |> set_engine('glmnet')
linear_reg() |> set_engine('stan')
linear_reg() |> set_engine('keras')
linear_reg() |> set_engine('spark')

rand_forest() |> set_engine('randomForest')
rand_forest() |> set_engine('ranger')
rand_forest() |> set_engine('keras')

boost_tree() |> set_engine('xgboost')
boost_tree(mode='classification') |> set_engine('xgboost')
```

```{r}
spec1 <- boost_tree(
    mode='classification',
    trees=100,
    tree_depth=4
) |> 
    set_engine('xgboost')
spec1
```


# Workflows

```{r}
library(workflows)
```

